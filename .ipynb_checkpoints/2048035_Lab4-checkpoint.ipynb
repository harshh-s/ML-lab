{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With suitable dataset explore the working of PCA and LDA and identify the differences in the working procedures of both the techniques. Provide sufficient inference based on your understanding and observations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Domain:** Marketing and Finance\n",
    "\n",
    "The aim is to implement PCA and LDA technique on credit card dataset to reduce the dimensionality of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset\n",
    "dataset = pd.read_csv(\"creditcard.csv\", nrows = 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V25       V26       V27       V28       V29  \\\n",
       "0  0.098698  0.363787  ...  0.128539 -0.189115  0.133558 -0.021053 -1.359807   \n",
       "1  0.085102 -0.255425  ...  0.167170  0.125895 -0.008983  0.014724  1.191857   \n",
       "2  0.247676 -1.514654  ... -0.327642 -0.139097 -0.055353 -0.059752 -1.358354   \n",
       "3  0.377436 -1.387024  ...  0.647376 -0.221929  0.062723  0.061458 -0.966272   \n",
       "4 -0.270533  0.817739  ... -0.206010  0.502292  0.219422  0.215153 -1.158233   \n",
       "\n",
       "        V30       V31       V32  Amount  Class  \n",
       "0 -0.072781  0.251412  0.066928  149.62      0  \n",
       "1  0.266151 -0.069083 -0.339846    2.69      0  \n",
       "2 -1.340163  0.524980 -0.689281  378.66      0  \n",
       "3 -0.185226 -0.208038 -1.175575  123.50      0  \n",
       "4  0.877737  0.408542  0.141267   69.99      0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Shape of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 35)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** There are 20000 rows and 31 columns in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Checking for missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "V29       0\n",
       "V30       0\n",
       "V31       0\n",
       "V32       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** There are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Checking for duplicate rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** There are duplicate rows present in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of LDA and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the values for x and y variable\n",
    "# Drop \"Class\" and assign it to target variable\n",
    "X = dataset.drop('Class', 1)\n",
    "y = dataset['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 34), (20000,))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 33), (4000, 33))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing constant features using variance threshold\n",
    "constant_filter = VarianceThreshold(threshold=0.10)\n",
    "\n",
    "#Applying the filter on the training set\n",
    "constant_filter.fit(X_train)\n",
    "\n",
    "#Remove constant features from training and test sets, we can use the transform() method of the constant_filter\n",
    "X_train_filter = constant_filter.transform(X_train)\n",
    "X_test_filter = constant_filter.transform(X_test)\n",
    "X_train_filter.shape, X_test_filter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of duplicated features in the dataset, We remove one of the feature\n",
    "X_train_T = X_train_filter.T\n",
    "X_test_T = X_test_filter.T\n",
    "X_train_T = pd.DataFrame(X_train_T)\n",
    "X_test_T =pd.DataFrame(X_test_T)\n",
    "X_train_T.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** We remove constant features from the data with the threshold value of 0.10. That means we remove the features which have 90% similarity among them. There are 4 similar columns in the dataset that are 99% similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_features = X_train_T.duplicated()\n",
    "features_to_keep = [not index for index in duplicated_features]\n",
    "X_train_unique = X_train_T[features_to_keep].T\n",
    "X_test_unique = X_test_T[features_to_keep].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 29), (4000, 29))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#standardize the data to get the same scale\n",
    "scaler = StandardScaler().fit(X_train_unique)\n",
    "X_train_unique = scaler.transform(X_train_unique)\n",
    "X_test_unique = scaler.transform(X_test_unique)\n",
    "X_train_unique = pd.DataFrame(X_train_unique)\n",
    "X_test_unique = pd.DataFrame(X_test_unique)\n",
    "X_train_unique.shape, X_test_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00749</td>\n",
       "      <td>-0.032406</td>\n",
       "      <td>-0.088782</td>\n",
       "      <td>0.027535</td>\n",
       "      <td>-0.085750</td>\n",
       "      <td>-0.043481</td>\n",
       "      <td>-0.054680</td>\n",
       "      <td>0.060932</td>\n",
       "      <td>-0.143732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010458</td>\n",
       "      <td>0.016940</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>0.021172</td>\n",
       "      <td>-0.007582</td>\n",
       "      <td>-0.014271</td>\n",
       "      <td>0.068058</td>\n",
       "      <td>-0.036429</td>\n",
       "      <td>-0.004840</td>\n",
       "      <td>0.038358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007490</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.307000</td>\n",
       "      <td>0.393050</td>\n",
       "      <td>-0.130860</td>\n",
       "      <td>0.177574</td>\n",
       "      <td>0.133403</td>\n",
       "      <td>0.300916</td>\n",
       "      <td>-0.160428</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000729</td>\n",
       "      <td>-0.126978</td>\n",
       "      <td>-0.112804</td>\n",
       "      <td>0.038699</td>\n",
       "      <td>-0.060782</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>-0.145021</td>\n",
       "      <td>-0.179951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.032406</td>\n",
       "      <td>-0.30700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.392820</td>\n",
       "      <td>0.167686</td>\n",
       "      <td>-0.233508</td>\n",
       "      <td>-0.067286</td>\n",
       "      <td>-0.155604</td>\n",
       "      <td>0.111692</td>\n",
       "      <td>-0.101254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020067</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.075179</td>\n",
       "      <td>-0.148909</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>-0.032123</td>\n",
       "      <td>-0.075669</td>\n",
       "      <td>-0.068357</td>\n",
       "      <td>0.141997</td>\n",
       "      <td>-0.461635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.088782</td>\n",
       "      <td>0.39305</td>\n",
       "      <td>-0.392820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.221292</td>\n",
       "      <td>0.377193</td>\n",
       "      <td>0.069352</td>\n",
       "      <td>0.503921</td>\n",
       "      <td>-0.365870</td>\n",
       "      <td>0.220517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043102</td>\n",
       "      <td>-0.146534</td>\n",
       "      <td>-0.034637</td>\n",
       "      <td>0.241149</td>\n",
       "      <td>0.045416</td>\n",
       "      <td>0.042289</td>\n",
       "      <td>-0.171517</td>\n",
       "      <td>0.064244</td>\n",
       "      <td>-0.197812</td>\n",
       "      <td>-0.121610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027535</td>\n",
       "      <td>-0.13086</td>\n",
       "      <td>0.167686</td>\n",
       "      <td>-0.221292</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.149768</td>\n",
       "      <td>-0.053925</td>\n",
       "      <td>-0.194087</td>\n",
       "      <td>0.123479</td>\n",
       "      <td>-0.154267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023042</td>\n",
       "      <td>0.018345</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-0.020486</td>\n",
       "      <td>-0.006054</td>\n",
       "      <td>-0.037724</td>\n",
       "      <td>-0.029984</td>\n",
       "      <td>0.053008</td>\n",
       "      <td>0.059111</td>\n",
       "      <td>0.118921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1         2         3         4         5         6   \\\n",
       "0  1.000000  0.00749 -0.032406 -0.088782  0.027535 -0.085750 -0.043481   \n",
       "1  0.007490  1.00000 -0.307000  0.393050 -0.130860  0.177574  0.133403   \n",
       "2 -0.032406 -0.30700  1.000000 -0.392820  0.167686 -0.233508 -0.067286   \n",
       "3 -0.088782  0.39305 -0.392820  1.000000 -0.221292  0.377193  0.069352   \n",
       "4  0.027535 -0.13086  0.167686 -0.221292  1.000000 -0.149768 -0.053925   \n",
       "\n",
       "         7         8         9   ...        19        20        21        22  \\\n",
       "0 -0.054680  0.060932 -0.143732  ... -0.010458  0.016940  0.008512  0.021172   \n",
       "1  0.300916 -0.160428  0.015538  ... -0.000729 -0.126978 -0.112804  0.038699   \n",
       "2 -0.155604  0.111692 -0.101254  ... -0.020067  0.004393  0.075179 -0.148909   \n",
       "3  0.503921 -0.365870  0.220517  ... -0.043102 -0.146534 -0.034637  0.241149   \n",
       "4 -0.194087  0.123479 -0.154267  ... -0.023042  0.018345  0.000559 -0.020486   \n",
       "\n",
       "         23        24        25        26        27        28  \n",
       "0 -0.007582 -0.014271  0.068058 -0.036429 -0.004840  0.038358  \n",
       "1 -0.060782  0.006162  0.153900  0.022847 -0.145021 -0.179951  \n",
       "2  0.010222 -0.032123 -0.075669 -0.068357  0.141997 -0.461635  \n",
       "3  0.045416  0.042289 -0.171517  0.064244 -0.197812 -0.121610  \n",
       "4 -0.006054 -0.037724 -0.029984  0.053008  0.059111  0.118921  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation matrix\n",
    "corrmat = X_train_unique.corr()\n",
    "corrmat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correlated features:  3\n"
     ]
    }
   ],
   "source": [
    "#Finding the number of correlated features\n",
    "def get_correlation(data, threshold):\n",
    "    corr_col = set()\n",
    "    corrmat = data.corr()\n",
    "    for i in range(len(corrmat.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corrmat.iloc[i, j]) > threshold:\n",
    "                colname = corrmat.columns[i]\n",
    "                corr_col.add(colname)\n",
    "    return corr_col\n",
    "\n",
    "corr_features = get_correlation(X_train_unique, 0.40)\n",
    "print('correlated features: ', len(set(corr_features)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** There are three correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 26), (4000, 26))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_uncorr = X_train_unique.drop(labels=corr_features, axis = 1)\n",
    "X_test_uncorr = X_test_unique.drop(labels = corr_features, axis = 1)\n",
    "X_train_uncorr.shape, X_test_uncorr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** we can observe that the features are reduced from 29 to 26 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Dimensionality Reduction by Linear Discriminant Analysis (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis is a supervised algorithm as it takes the class label into consideration. It is a way to reduce â€˜dimensionalityâ€™ while at the same time preserving as much of the class discrimination information as possible.\n",
    "\n",
    "LDA helps you find the boundaries around clusters of classes. It projects your data points on a line so that your clusters are as separated as possible, with each cluster having a relative (close) distance to a centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the data by using fit_transform()\n",
    "lda = LDA(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train_uncorr, y_train)\n",
    "X_test_lda = lda.transform(X_test_uncorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 1), (4000, 1))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Transformed data\n",
    "X_train_lda.shape, X_test_lda.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def run_randomForest(X_train, X_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print('Accuracy on test set: ')\n",
    "    print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: \n",
      "0.9975\n",
      "Wall time: 301 ms\n"
     ]
    }
   ],
   "source": [
    "#Running this on the transformed dataset\n",
    "%%time\n",
    "run_randomForest(X_train_lda, X_test_lda, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: \n",
      "0.99825\n",
      "Wall time: 884 ms\n"
     ]
    }
   ],
   "source": [
    "#Running this on the original dataset\n",
    "%%time\n",
    "run_randomForest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Accuracy on the original dataset is more as compared to transformed dataset. But, the training time original dataset is double than tranformed version and the dimension also has been reduced.\n",
    "From this, we can observe LDA wonâ€™t guarantee on the accuracy but it will give guarantee on the reduction in dimension and CPU time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Dimensionality Reduction by Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is that it is an Unsupervised dimensionality reduction technique, you can cluster the similar data points based on the feature correlation between them without any supervision (or labels)\n",
    "\n",
    "Principal Component Analysis (PCA) is a linear dimensionality reduction technique that can be utilized for extracting information from a high-dimensional space by projecting it into a lower-dimensional sub-space. It tries to preserve the essential parts that have more variation of the data and remove the non-essential parts with fewer variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=2, random_state=42)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing the features\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "pca.fit(X_train_uncorr)\n",
    "PCA(copy=True, iterated_power='auto', n_components=2, random_state=42, svd_solver='auto', tol=0.0, whiten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 2), (4000, 2))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training and testing dataset by PCA transformation\n",
    "X_train_pca = pca.transform(X_train_uncorr)\n",
    "X_test_pca = pca.transform(X_test_uncorr)\n",
    "X_train_pca.shape, X_test_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: \n",
      "0.99775\n",
      "Wall time: 364 ms\n"
     ]
    }
   ],
   "source": [
    "#Running this on the transformed dataset\n",
    "%%time\n",
    "run_randomForest(X_train_pca, X_test_pca, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: \n",
      "0.99825\n",
      "Wall time: 883 ms\n"
     ]
    }
   ],
   "source": [
    "#Running this on the original dataset\n",
    "%%time\n",
    "run_randomForest(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Components:  1\n",
      "Accuracy on test set: \n",
      "0.9945\n",
      "\n",
      "Selected Components:  2\n",
      "Accuracy on test set: \n",
      "0.99775\n",
      "\n",
      "Selected Components:  3\n",
      "Accuracy on test set: \n",
      "0.99775\n",
      "\n",
      "Selected Components:  4\n",
      "Accuracy on test set: \n",
      "0.99825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the accuracy for various selected components\n",
    "for component in range(1,5):\n",
    "    pca = PCA(n_components=component, random_state=42)\n",
    "    pca.fit(X_train_uncorr)\n",
    "    X_train_pca = pca.transform(X_train_uncorr)\n",
    "    X_test_pca = pca.transform(X_test_uncorr)\n",
    "    print('Selected Components: ', component)\n",
    "    run_randomForest(X_train_pca, X_test_pca, y_train, y_test)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** Component 4 is the best fit for the model as it shows maximum accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
