{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Georgia\" size=3>\n",
    "    \n",
    "Harsh Seksaria\n",
    "    \n",
    "2048011\n",
    "    \n",
    "2 - MDS\n",
    "    \n",
    "---\n",
    "    \n",
    "Machine Learning Lab - 5 and 6\n",
    "    \n",
    "    ANN, SVM and Logistic Regression\n",
    "    \n",
    "    18 March, 2021\n",
    "    \n",
    "---\n",
    "    \n",
    "CHRIST (Deemed to be University)\n",
    "    \n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML Libraries\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=Georgia>Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "\n",
    "# Assign colum names to the dataset\n",
    "colnames = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']\n",
    "\n",
    "# Read dataset in dataframe\n",
    "data = pd.read_csv(url, names=colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal-length    0\n",
       "sepal-width     0\n",
       "petal-length    0\n",
       "petal-width     0\n",
       "Class           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing dataset into x and y\n",
    "x = data.drop('Class', axis=1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing dataset into training and testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.25, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=Georgia>Artificial Neural Networks</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 528 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000)\n",
    "mlp.fit(X_train, Y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=Garamond>Prediction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_ann = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-virginica', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-versicolor'],\n",
       "      dtype='<U15')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the predictions\n",
    "Y_pred_ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=Garamond>Evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT:\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        12\n",
      "Iris-versicolor       0.92      1.00      0.96        11\n",
      " Iris-virginica       1.00      0.93      0.97        15\n",
      "\n",
      "       accuracy                           0.97        38\n",
      "      macro avg       0.97      0.98      0.97        38\n",
      "   weighted avg       0.98      0.97      0.97        38\n",
      "\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "\n",
      " [[12  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  1 14]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"CLASSIFICATION REPORT:\\n\\n\", classification_report(Y_test, Y_pred_ann))\n",
    "print(\"\\nCONFUSION MATRIX:\\n\\n\", confusion_matrix(Y_test, Y_pred_ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=Garamond size=3>Advantages of ANN</font>\n",
    "\n",
    "1. Ability to work with incomplete knowledge\n",
    "2. Information such as in traditional programming is stored on the entire network, not on a database\n",
    "3. Fault tolerance- Eeen if one node fails, others keep working successfully\n",
    "4. Parallel Processing\n",
    "5. Having a distributed memory\n",
    "\n",
    "<font face=Garamond size=3>Disadvantages of ANN</font>\n",
    "\n",
    "1. Hardware dependence\n",
    "2. Unexplained behaviour of the network\n",
    "3. Execution duration\n",
    "4. Difficulty of showing the problem to the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=Georgia>Support Vector Machine</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=Garamond>Model - Gaussian Kernel</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "svcclassifier = SVC(kernel=\"rbf\")\n",
    "svcclassifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=Garamond>Prediction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_svm = svcclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-virginica', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the predictions\n",
    "Y_pred_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=Garamond>Evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT:\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        12\n",
      "Iris-versicolor       0.83      0.91      0.87        11\n",
      " Iris-virginica       0.93      0.87      0.90        15\n",
      "\n",
      "       accuracy                           0.92        38\n",
      "      macro avg       0.92      0.93      0.92        38\n",
      "   weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "\n",
      " [[12  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  2 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(\"CLASSIFICATION REPORT:\\n\\n\", classification_report(Y_test, Y_pred_svm))\n",
    "print(\"\\nCONFUSION MATRIX:\\n\\n\", confusion_matrix(Y_test, Y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=Garamond size=3>Advantages of SVM</font>\n",
    "\n",
    "1. SVM works relatively well when there is a clear margin of separation between classes\n",
    "2. SVM is more effective in high dimensional spaces\n",
    "3. SVM is effective in cases where the number of dimensions is greater than the number of samples\n",
    "4. SVM is relatively memory efficient\n",
    "\n",
    "\n",
    "<font face=Garamond size=3>Disadvantages of SVM</font>\n",
    "\n",
    "1. SVM algorithm is not suitable for large data sets\n",
    "2. SVM does not perform very well when the data set has more noise i.e. target classes are overlapping\n",
    "3. In cases where the number of features for each data point exceeds the number of training data samples, the SVM will underperform\n",
    "4. As the support vector classifier works by putting data points, above and below the classifying hyperplane there is no probabilistic explanation for the classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font face=Georgia>Logistic Regression</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=Garamond>Model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 47.9 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=Garamond>Prediction</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_lr = svcclassifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-virginica', 'Iris-virginica', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-virginica', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-versicolor',\n",
       "       'Iris-versicolor', 'Iris-versicolor', 'Iris-versicolor',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-virginica',\n",
       "       'Iris-virginica', 'Iris-versicolor', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-setosa', 'Iris-virginica',\n",
       "       'Iris-versicolor', 'Iris-setosa', 'Iris-versicolor', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-setosa', 'Iris-setosa',\n",
       "       'Iris-virginica', 'Iris-virginica', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Printing the predictions\n",
    "Y_pred_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font face=Garamond>Evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT:\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        12\n",
      "Iris-versicolor       0.83      0.91      0.87        11\n",
      " Iris-virginica       0.93      0.87      0.90        15\n",
      "\n",
      "       accuracy                           0.92        38\n",
      "      macro avg       0.92      0.93      0.92        38\n",
      "   weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "\n",
      " [[12  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  2 13]]\n",
      "\n",
      "ACCURACY SCORE:  0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"CLASSIFICATION REPORT:\\n\\n\", classification_report(Y_test, Y_pred_lr))\n",
    "print(\"\\nCONFUSION MATRIX:\\n\\n\", confusion_matrix(Y_test, Y_pred_lr))\n",
    "print(\"\\nACCURACY SCORE: \", accuracy_score(Y_test, Y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=Garamond size=3>Advantages of Logistic Regression</font>\n",
    "\n",
    "1. Logistic regression is easier to implement, interpret, and very efficient to train\n",
    "2. It makes no assumptions about distributions of classes in feature space\n",
    "3. It can easily extend to multiple classes(multinomial regression) and a natural probabilistic view of class predictions\n",
    "4. It is very fast at classifying unknown records\n",
    "\n",
    "<font face=Garamond size=3>Disadvantages of Logistic Regression</font>\n",
    "\n",
    "1. If the number of observations is lesser than the number of features, Logistic Regression should not be used, otherwise, it may lead to overfitting\n",
    "2. It constructs linear boundaries\n",
    "3. The major limitation of Logistic Regression is the assumption of linearity between the dependent variable and the independent variables\n",
    "4. Non-linear problems can’t be solved with logistic regression because it has a linear decision surface. Linearly separable data is rarely found in real-world scenarios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
